{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Flatten, Dropout, MaxPooling2D,BatchNormalization\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES = np.array([])\n",
    "for i in range(10):\n",
    "    CLASS_NAMES =np.append(CLASS_NAMES,chr(ord(\"0\")+i))\n",
    "for i in range(26):\n",
    "    CLASS_NAMES = np.append(CLASS_NAMES,chr(ord(\"A\")+i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no crop function\n",
    "def parse_label(strIN):\n",
    "    return (strIN==CLASS_NAMES).astype(float)\n",
    "def readimg_to_tensor(fn):\n",
    "    a = tf.io.read_file((fn))\n",
    "    img = tf.io.decode_jpeg(a)\n",
    "    img = tf.image.convert_image_dtype(img, dtype=tf.float16)/255.\n",
    "    img = tf.image.per_image_standardization(img)\n",
    "    return img\n",
    "def parseResult(RS):\n",
    "    for j in range(len(RS[0])):\n",
    "        PredChr=''\n",
    "        for i in range(6):\n",
    "            PredChr+= CLASS_NAMES[(np.where(RS[i][j] == RS[i][j].max())[0][0])]\n",
    "        if j == 0:\n",
    "            LB = [PredChr]\n",
    "        else:\n",
    "            LB.append(PredChr)      \n",
    "    return LB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data 02\n",
    "def prepData02_test(): \n",
    "  train_dir_data02 = os.path.abspath(os.getcwd())+\"/train/data02_train/\"\n",
    "  data2 = pd.read_csv(\"./train/data02_train.csv\")\n",
    "  for i in range(len(data2)):\n",
    "      data2.iloc[i,1] = list(data2.iloc[i,1])\n",
    "  arr = np.zeros([6,50000],str)\n",
    "  for j in range(6):\n",
    "      for i in range(len(data2)):\n",
    "          arr[j][i] = data2.iloc[i,1][j]\n",
    "  data2 = data2.drop(columns= [\"code\"]).join(pd.DataFrame(arr.transpose(),columns = [\"code0\",\"code1\",'code2','code3','code4','code5']))\n",
    "\n",
    "  #to one hot\n",
    "  for i in range(6):\n",
    "      data2.iloc[:,i+1] = data2.iloc[:,i+1].map(parse_label)\n",
    "\n",
    "  TL = tf.convert_to_tensor(list(data2.iloc[:,1].values))\n",
    "  TL2 = tf.convert_to_tensor(list(data2.iloc[:,2].values))\n",
    "  TL3 = tf.convert_to_tensor(list(data2.iloc[:,3].values))\n",
    "  TL4 = tf.convert_to_tensor(list(data2.iloc[:,4].values))\n",
    "  TL5 = tf.convert_to_tensor(list(data2.iloc[:,5].values))\n",
    "  TL6 = tf.convert_to_tensor(list(data2.iloc[:,6].values))\n",
    "\n",
    "  train_dir2 = tf.data.Dataset.list_files(train_dir_data02+'*.jpg',shuffle=False)\n",
    "  train_dir2 = train_dir2.shuffle(50000,seed=1)\n",
    "  test_dir2 = train_dir2.skip(45000)\n",
    "\n",
    "  train_label2 = tf.data.Dataset.from_tensor_slices((TL,TL2,TL3,TL4,TL5,TL6))\n",
    "  train_label2 = train_label2.shuffle(50000,seed=1)\n",
    "  test_label2 = train_label2.skip(45000)\n",
    "\n",
    "  test_data2 = test_dir2.map(lambda x: readimg_to_tensor(x))\n",
    "  test_data2 = tf.data.Dataset.zip((test_data2,test_label2))\n",
    "  test_data2 = test_data2.batch(5000)\n",
    "\n",
    "\n",
    "  img_test , lb_test = next(iter(test_data2))\n",
    "  return  img_test, lb_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_test, lb_test= prepData02_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allright(inputdata,label):\n",
    "    '''calculate the accuracy of each digit and of all right'''\n",
    "    a = np.argmax(inputdata,axis = 2)\n",
    "    b = np.argmax(lb_test[0],axis=1)\n",
    "    b = np.expand_dims(b,0)\n",
    "    for i in range(5):\n",
    "        b = np.concatenate((b,np.expand_dims(np.argmax(lb_test[i+1],axis=1),0)),axis=0)\n",
    "    acc_digit = np.mean(a==b,axis=1)\n",
    "    acc_all = np.mean(np.all(a.transpose()==b.transpose(),axis=1))\n",
    "    return acc_digit,acc_all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allright_ense(inputdata,label):\n",
    "    '''calculate the accuracy of each digit and of all right'''\n",
    "    a = inputdata.transpose()\n",
    "    b = np.argmax(lb_test[0],axis=1)\n",
    "    b = np.expand_dims(b,0)\n",
    "    for i in range(5):\n",
    "        b = np.concatenate((b,np.expand_dims(np.argmax(lb_test[i+1],axis=1),0)),axis=0)\n",
    "    acc_digit = np.mean(a==b,axis=1)\n",
    "    acc_all = np.mean(np.all(a.transpose()==b.transpose(),axis=1))\n",
    "    return acc_digit,acc_all "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"h5s/data02/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_paths=[\"CNN_GRU_4.hdf5\",\"CNN_GRU_5.hdf5\"]\n",
    "#\"CNN_GRU_3_fine.hdf5\",,\"CNN+GRU.hdf5\",\"CNN_GRU_2.hdf5\"\"railway_d2e-1.hdf5\",\"CNN_GRU_3_fine2.hdf5\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble(model_paths):\n",
    "    '''return the most probable character index for given models'''\n",
    "    models = []\n",
    "    for m in model_paths:\n",
    "        models.append(tf.keras.models.load_model(filepath+m))\n",
    "    result = []\n",
    "    for m in models:\n",
    "        result.append(m.predict(img_test))\n",
    "    r = np.array(result)\n",
    "    for i,m in zip(r,model_paths):\n",
    "        print('{}   {}'.format(m,allright(i,lb_test)))\n",
    "    a = np.argmax(r,axis=3)\n",
    "    a = a.transpose()\n",
    "    a_p = np.max(r,axis=3)\n",
    "    a_p = a_p.transpose()\n",
    "\n",
    "    #return the most probable character index\n",
    "    vote_outcome=[]\n",
    "    for j in range(len(a)):\n",
    "        chr = []\n",
    "        for i,p in zip(a[j],a_p[j]):\n",
    "            if(all(i==i[0])):\n",
    "                chr.append(i[0])\n",
    "            else:\n",
    "                chr.append(i[np.argmax(p)])        \n",
    "        vote_outcome.append(chr)\n",
    "    vote_outcome = np.array(vote_outcome)\n",
    "    print(allright_ense(vote_outcome,lb_test))\n",
    "\n",
    "    #return the most voted character index\n",
    "    vote_outcome2=[]\n",
    "    for j in range(len(a)):\n",
    "        chr = []\n",
    "        for i,p in zip(a[j],a_p[j]):\n",
    "            if(all(i==i[0])):\n",
    "                chr.append(i[0])\n",
    "            else:\n",
    "                chr.append(np.bincount(i).argmax())       \n",
    "        vote_outcome2.append(chr)\n",
    "    vote_outcome2 = np.array(vote_outcome2)\n",
    "    print(allright_ense(vote_outcome2,lb_test))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_chr(model_paths):\n",
    "    '''return the most probable characters for given models'''\n",
    "    models = []\n",
    "    for m in model_paths:\n",
    "        models.append(tf.keras.models.load_model(filepath+m))\n",
    "    result = []\n",
    "    for m in models:\n",
    "        result.append(m.predict(img_test))\n",
    "    r = np.array(result)\n",
    "    a = np.argmax(r,axis=3)\n",
    "    a = a.transpose()\n",
    "    a_p = np.max(r,axis=3)\n",
    "    a_p = a_p.transpose()\n",
    "    #return the most probable character index\n",
    "    vote_outcome=[]\n",
    "    for j in range(len(a)):\n",
    "        chr = ''\n",
    "        for i,p in zip(a[j],a_p[j]):\n",
    "            if(all(i==i[0])):\n",
    "                chr+=(CLASS_NAMES[i[0]])\n",
    "            else:\n",
    "                maj = np.bincount(i).argmax()   #i[np.argmax(p)]\n",
    "                chr+=(CLASS_NAMES[maj])           \n",
    "        vote_outcome.append(chr)\n",
    "    \n",
    "    return vote_outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CNN_GRU_4.hdf5   (array([0.994 , 0.9946, 0.9924, 0.996 , 0.9948, 0.9928]), 0.9656)\nCNN_GRU_5.hdf5   (array([0.994 , 0.9938, 0.9936, 0.9958, 0.9952, 0.993 ]), 0.9666)\n(array([0.9948, 0.9946, 0.9942, 0.997 , 0.9954, 0.9946]), 0.9712)\n(array([0.9946, 0.994 , 0.9932, 0.996 , 0.9956, 0.9932]), 0.968)\n"
    }
   ],
   "source": [
    "ensemble(model_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 紀錄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## val 02 \n",
    "1. 97.44%   多數決\n",
    "\n",
    "model_paths=[\"CNN_GRU_3_fine.hdf5\",\"railway_d2e-1.hdf5\",\"CNN_GRU_3_fine2.hdf5\",\"CNN_GRU_4.hdf5\",\"CNN_GRU_5.hdf5\",\"CNN+GRU.hdf5\",\"CNN_GRU_2.hdf5\"]   \n",
    "\n",
    "2. 97.46%   多數決\n",
    "\n",
    "model_paths=[\"railway_d2e-1.hdf5\",\"CNN_GRU_3_fine2.hdf5\",\"CNN_GRU_4.hdf5\",\"CNN_GRU_5.hdf5\",\"CNN+GRU.hdf5\",\"CNN_GRU_2.hdf5\"] \n",
    "\n",
    "3. 97.32%    多數決\n",
    "\n",
    "model_paths=[\"CNN_GRU_3_fine2.hdf5\",\"CNN_GRU_4.hdf5\",\"CNN_GRU_5.hdf5\",\"CNN+GRU.hdf5\",\"CNN_GRU_2.hdf5\"]\n",
    "\n",
    "4. 97.3%    多數決\n",
    "\n",
    "model_paths=[\"CNN_GRU_3_fine.hdf5\",\"CNN_GRU_3_fine2.hdf5\",\"CNN_GRU_4.hdf5\",\"CNN_GRU_5.hdf5\",\"CNN+GRU.hdf5\",\"CNN_GRU_2.hdf5\"]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitmyenvcondac89683127ca741bc84ed6db3ffcad32d",
   "display_name": "Python 3.7.7 64-bit ('myenv': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}