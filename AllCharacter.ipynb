{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train data count: 50000\nValidation data count: 10000\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         filename code0 code1 code2 code3 code4 code5\n0      000000.jpg     Z     3     2     7     0     D\n1      000001.jpg     V     M     Y     X     E     8\n2      000002.jpg     J     Z     K     W     V     U\n3      000003.jpg     X     9     I     2     7     H\n4      000004.jpg     H     5     X     G     R     2\n...           ...   ...   ...   ...   ...   ...   ...\n49995  049995.jpg     3     Y     F     I     S     E\n49996  049996.jpg     4     S     U     T     F     7\n49997  049997.jpg     C     Y     U     N     0     9\n49998  049998.jpg     K     C     D     8     I     O\n49999  049999.jpg     8     X     L     C     2     V\n\n[50000 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>code0</th>\n      <th>code1</th>\n      <th>code2</th>\n      <th>code3</th>\n      <th>code4</th>\n      <th>code5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000000.jpg</td>\n      <td>Z</td>\n      <td>3</td>\n      <td>2</td>\n      <td>7</td>\n      <td>0</td>\n      <td>D</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000001.jpg</td>\n      <td>V</td>\n      <td>M</td>\n      <td>Y</td>\n      <td>X</td>\n      <td>E</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000002.jpg</td>\n      <td>J</td>\n      <td>Z</td>\n      <td>K</td>\n      <td>W</td>\n      <td>V</td>\n      <td>U</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>000003.jpg</td>\n      <td>X</td>\n      <td>9</td>\n      <td>I</td>\n      <td>2</td>\n      <td>7</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>000004.jpg</td>\n      <td>H</td>\n      <td>5</td>\n      <td>X</td>\n      <td>G</td>\n      <td>R</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49995</th>\n      <td>049995.jpg</td>\n      <td>3</td>\n      <td>Y</td>\n      <td>F</td>\n      <td>I</td>\n      <td>S</td>\n      <td>E</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>049996.jpg</td>\n      <td>4</td>\n      <td>S</td>\n      <td>U</td>\n      <td>T</td>\n      <td>F</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>049997.jpg</td>\n      <td>C</td>\n      <td>Y</td>\n      <td>U</td>\n      <td>N</td>\n      <td>0</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>049998.jpg</td>\n      <td>K</td>\n      <td>C</td>\n      <td>D</td>\n      <td>8</td>\n      <td>I</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>049999.jpg</td>\n      <td>8</td>\n      <td>X</td>\n      <td>L</td>\n      <td>C</td>\n      <td>2</td>\n      <td>V</td>\n    </tr>\n  </tbody>\n</table>\n<p>50000 rows Ã— 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Flatten, Dropout, MaxPooling2D,BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "training_size = 300000\n",
    "batch_size = 128\n",
    "epochs = 15\n",
    "IMG_HEIGHT = 60\n",
    "IMG_WIDTH = 28\n",
    "\n",
    "CLASS_NAMES = np.array([])\n",
    "for i in range(10):\n",
    "    CLASS_NAMES =np.append(CLASS_NAMES,chr(ord(\"0\")+i))\n",
    "for i in range(26):\n",
    "    CLASS_NAMES = np.append(CLASS_NAMES,chr(ord(\"A\")+i))\n",
    "\n",
    "#training dir / validation dir\n",
    "train_dir_data01 = os.path.abspath(os.getcwd())+\"\\\\train\\\\data01_train\\\\\"\n",
    "val_dir_data01 = os.path.abspath(os.getcwd())+\"\\\\dev\\\\data01_dev\"\n",
    "num_train_data01 = len(os.listdir(train_dir_data01))\n",
    "num_val_data01 = len(os.listdir(val_dir_data01))\n",
    "print(\"Train data count: \" + str(num_train_data01))\n",
    "print(\"Validation data count: \" + str(num_val_data01))\n",
    "\n",
    "#store filename and label to a Dataframe \n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"train\\\\data01_train.csv\")\n",
    "for i in range(len(data)):\n",
    "    data.iloc[i,1] = list(data.iloc[i,1])\n",
    "\n",
    "#maybe there's an easier way to separate labels??\n",
    "arr = np.zeros([6,50000],str)\n",
    "for j in range(6):\n",
    "    for i in range(len(data)):\n",
    "        arr[j][i] = data.iloc[i,1][j]\n",
    "data = data.drop(columns= [\"code\"]).join(pd.DataFrame(arr.transpose(),columns = [\"code0\",\"code1\",'code2','code3','code4','code5']))\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no crop function\n",
    "def parse_label(strIN):\n",
    "    return (strIN==CLASS_NAMES).astype(float)\n",
    "def readimg_to_tensor(fn):\n",
    "    a = tf.io.read_file((fn))\n",
    "        #crop to [60,30,3]\n",
    "    img = tf.io.decode_jpeg(a)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         filename                                              code0  \\\n0      000000.jpg  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n1      000001.jpg  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n2      000002.jpg  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n3      000003.jpg  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n4      000004.jpg  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n...           ...                                                ...   \n49995  049995.jpg  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n49996  049996.jpg  [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...   \n49997  049997.jpg  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n49998  049998.jpg  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n49999  049999.jpg  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...   \n\n                                                   code1  \\\n0      [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n1      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n2      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n3      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n4      [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...   \n...                                                  ...   \n49995  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n49996  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n49997  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n49998  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n49999  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n\n                                                   code2  \\\n0      [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n1      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n2      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n3      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n4      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n...                                                  ...   \n49995  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n49996  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n49997  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n49998  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n49999  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n\n                                                   code3  \\\n0      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   \n1      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n2      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n3      [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n4      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n...                                                  ...   \n49995  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n49996  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n49997  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n49998  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...   \n49999  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n\n                                                   code4  \\\n0      [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n1      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n2      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n3      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   \n4      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n...                                                  ...   \n49995  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n49996  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n49997  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n49998  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n49999  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n\n                                                   code5  \n0      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n1      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...  \n2      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n3      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n4      [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n...                                                  ...  \n49995  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n49996  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...  \n49997  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n49998  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n49999  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n\n[50000 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>code0</th>\n      <th>code1</th>\n      <th>code2</th>\n      <th>code3</th>\n      <th>code4</th>\n      <th>code5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000000.jpg</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000001.jpg</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000002.jpg</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>000003.jpg</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>000004.jpg</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49995</th>\n      <td>049995.jpg</td>\n      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>049996.jpg</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>049997.jpg</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>049998.jpg</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>049999.jpg</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>50000 rows Ã— 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "#to one hot\n",
    "for i in range(6):\n",
    "    data.iloc[:,i+1] = data.iloc[:,i+1].map(parse_label)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TL = tf.convert_to_tensor(list(data.iloc[:,1].values))\n",
    "TL2 = tf.convert_to_tensor(list(data.iloc[:,2].values))\n",
    "TL3 = tf.convert_to_tensor(list(data.iloc[:,3].values))\n",
    "TL4 = tf.convert_to_tensor(list(data.iloc[:,4].values))\n",
    "TL5 = tf.convert_to_tensor(list(data.iloc[:,5].values))\n",
    "TL6 = tf.convert_to_tensor(list(data.iloc[:,6].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no crop\n",
    "train_dir = tf.data.Dataset.list_files(train_dir_data01+'*.jpg',shuffle=False) \n",
    "train_data = train_dir.map(lambda x: readimg_to_tensor(x))\n",
    "train_label = tf.data.Dataset.from_tensor_slices((TL,TL2,TL3,TL4,TL5,TL6))\n",
    "train_data01=tf.data.Dataset.zip((train_data,train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation data no crop\n",
    "val_dir = tf.data.Dataset.list_files(val_dir_data01+'*.jpg',shuffle=False) \n",
    "val_data01 = val_dir.map(lambda x: readimg_to_tensor(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Creating CNN model...\nModel: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 60, 200, 3)] 0                                            \n__________________________________________________________________________________________________\nconv2d (Conv2D)                 (None, 60, 200, 32)  896         input_1[0][0]                    \n__________________________________________________________________________________________________\nconv2d_1 (Conv2D)               (None, 58, 198, 32)  9248        conv2d[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization (BatchNorma (None, 58, 198, 32)  128         conv2d_1[0][0]                   \n__________________________________________________________________________________________________\nmax_pooling2d (MaxPooling2D)    (None, 29, 99, 32)   0           batch_normalization[0][0]        \n__________________________________________________________________________________________________\ndropout (Dropout)               (None, 29, 99, 32)   0           max_pooling2d[0][0]              \n__________________________________________________________________________________________________\nconv2d_2 (Conv2D)               (None, 29, 99, 64)   18496       dropout[0][0]                    \n__________________________________________________________________________________________________\nconv2d_3 (Conv2D)               (None, 27, 97, 64)   36928       conv2d_2[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_1 (BatchNor (None, 27, 97, 64)   256         conv2d_3[0][0]                   \n__________________________________________________________________________________________________\nmax_pooling2d_1 (MaxPooling2D)  (None, 13, 48, 64)   0           batch_normalization_1[0][0]      \n__________________________________________________________________________________________________\ndropout_1 (Dropout)             (None, 13, 48, 64)   0           max_pooling2d_1[0][0]            \n__________________________________________________________________________________________________\nconv2d_4 (Conv2D)               (None, 13, 48, 128)  73856       dropout_1[0][0]                  \n__________________________________________________________________________________________________\nconv2d_5 (Conv2D)               (None, 11, 46, 128)  147584      conv2d_4[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_2 (BatchNor (None, 11, 46, 128)  512         conv2d_5[0][0]                   \n__________________________________________________________________________________________________\nmax_pooling2d_2 (MaxPooling2D)  (None, 5, 23, 128)   0           batch_normalization_2[0][0]      \n__________________________________________________________________________________________________\ndropout_2 (Dropout)             (None, 5, 23, 128)   0           max_pooling2d_2[0][0]            \n__________________________________________________________________________________________________\nconv2d_6 (Conv2D)               (None, 3, 21, 256)   295168      dropout_2[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_3 (BatchNor (None, 3, 21, 256)   1024        conv2d_6[0][0]                   \n__________________________________________________________________________________________________\nmax_pooling2d_3 (MaxPooling2D)  (None, 1, 10, 256)   0           batch_normalization_3[0][0]      \n__________________________________________________________________________________________________\nflatten (Flatten)               (None, 2560)         0           max_pooling2d_3[0][0]            \n__________________________________________________________________________________________________\ndropout_3 (Dropout)             (None, 2560)         0           flatten[0][0]                    \n__________________________________________________________________________________________________\ndigit1 (Dense)                  (None, 36)           92196       dropout_3[0][0]                  \n__________________________________________________________________________________________________\ndigit2 (Dense)                  (None, 36)           92196       dropout_3[0][0]                  \n__________________________________________________________________________________________________\ndigit3 (Dense)                  (None, 36)           92196       dropout_3[0][0]                  \n__________________________________________________________________________________________________\ndigit4 (Dense)                  (None, 36)           92196       dropout_3[0][0]                  \n__________________________________________________________________________________________________\ndigit5 (Dense)                  (None, 36)           92196       dropout_3[0][0]                  \n__________________________________________________________________________________________________\ndigit6 (Dense)                  (None, 36)           92196       dropout_3[0][0]                  \n==================================================================================================\nTotal params: 1,137,272\nTrainable params: 1,136,312\nNon-trainable params: 960\n__________________________________________________________________________________________________\n"
    }
   ],
   "source": [
    "#railway model\n",
    "print(\"Creating CNN model...\")\n",
    "inn = Input((60, 200, 3))\n",
    "out = inn\n",
    "out = Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu')(out)\n",
    "out = Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = MaxPooling2D(pool_size=(2, 2))(out)\n",
    "out = Dropout(0.3)(out)\n",
    "out = Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu')(out)\n",
    "out = Conv2D(filters=64, kernel_size=(3, 3), activation='relu')(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = MaxPooling2D(pool_size=(2, 2))(out)\n",
    "out = Dropout(0.3)(out)\n",
    "out = Conv2D(filters=128, kernel_size=(3, 3), padding='same', activation='relu')(out)\n",
    "out = Conv2D(filters=128, kernel_size=(3, 3), activation='relu')(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = MaxPooling2D(pool_size=(2, 2))(out)\n",
    "out = Dropout(0.3)(out)\n",
    "out = Conv2D(filters=256, kernel_size=(3, 3), activation='relu')(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = MaxPooling2D(pool_size=(2, 2))(out)\n",
    "out = Flatten()(out)\n",
    "sep = Dropout(0.3)(out)\n",
    "dig1 = Dense(36, name='digit1', activation='softmax')(sep)\n",
    "dig2 = Dense(36, name='digit2', activation='softmax')(sep)\n",
    "dig3 = Dense(36, name='digit3', activation='softmax')(sep)\n",
    "dig4 = Dense(36, name='digit4', activation='softmax')(sep)\n",
    "dig5 = Dense(36, name='digit5', activation='softmax')(sep)\n",
    "dig6 = Dense(36, name='digit6', activation='softmax')(sep)\n",
    "model = tf.keras.models.Model(inputs=inn, outputs=[dig1, dig2,dig3,dig4,dig5,dig6])\n",
    "model.compile(\n",
    "    loss=[\n",
    "        tf.keras.losses.CategoricalCrossentropy(),\n",
    "        tf.keras.losses.CategoricalCrossentropy(),\n",
    "        tf.keras.losses.CategoricalCrossentropy(),\n",
    "        tf.keras.losses.CategoricalCrossentropy(),\n",
    "        tf.keras.losses.CategoricalCrossentropy(),\n",
    "        tf.keras.losses.CategoricalCrossentropy(),\n",
    "    ],\n",
    "    optimizer='adam', \n",
    "    metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "50000"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "#number of element\n",
    "num_elements = tf.data.experimental.cardinality(train_data01).numpy()\n",
    "num_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "5986 - val_digit5_loss: 3.5561 - val_digit6_loss: 3.5902 - val_digit1_accuracy: 0.0420 - val_digit2_accuracy: 0.0360 - val_digit3_accuracy: 0.0440 - val_digit4_accuracy: 0.0380 - val_digit5_accuracy: 0.0400 - val_digit6_accuracy: 0.0220\nEpoch 8/15\n36/36 - 7s - loss: 19.8060 - digit1_loss: 3.3175 - digit2_loss: 3.2603 - digit3_loss: 3.2790 - digit4_loss: 3.3124 - digit5_loss: 3.3142 - digit6_loss: 3.3227 - digit1_accuracy: 0.0827 - digit2_accuracy: 0.1049 - digit3_accuracy: 0.1004 - digit4_accuracy: 0.0916 - digit5_accuracy: 0.0889 - digit6_accuracy: 0.0891 - val_loss: 21.4805 - val_digit1_loss: 3.5796 - val_digit2_loss: 3.6028 - val_digit3_loss: 3.6153 - val_digit4_loss: 3.5859 - val_digit5_loss: 3.5392 - val_digit6_loss: 3.5577 - val_digit1_accuracy: 0.0520 - val_digit2_accuracy: 0.0320 - val_digit3_accuracy: 0.0360 - val_digit4_accuracy: 0.0360 - val_digit5_accuracy: 0.0340 - val_digit6_accuracy: 0.0280\nEpoch 9/15\n36/36 - 7s - loss: 19.5265 - digit1_loss: 3.2763 - digit2_loss: 3.1973 - digit3_loss: 3.2116 - digit4_loss: 3.2588 - digit5_loss: 3.2797 - digit6_loss: 3.3028 - digit1_accuracy: 0.1036 - digit2_accuracy: 0.1184 - digit3_accuracy: 0.1084 - digit4_accuracy: 0.0980 - digit5_accuracy: 0.0913 - digit6_accuracy: 0.0907 - val_loss: 20.5537 - val_digit1_loss: 3.4414 - val_digit2_loss: 3.4623 - val_digit3_loss: 3.4176 - val_digit4_loss: 3.4342 - val_digit5_loss: 3.3381 - val_digit6_loss: 3.4601 - val_digit1_accuracy: 0.0680 - val_digit2_accuracy: 0.0580 - val_digit3_accuracy: 0.0620 - val_digit4_accuracy: 0.0800 - val_digit5_accuracy: 0.1140 - val_digit6_accuracy: 0.0480\nEpoch 10/15\n36/36 - 7s - loss: 18.7732 - digit1_loss: 3.1442 - digit2_loss: 3.0729 - digit3_loss: 3.0710 - digit4_loss: 3.1404 - digit5_loss: 3.1596 - digit6_loss: 3.1851 - digit1_accuracy: 0.1178 - digit2_accuracy: 0.1329 - digit3_accuracy: 0.1333 - digit4_accuracy: 0.1222 - digit5_accuracy: 0.1173 - digit6_accuracy: 0.1107 - val_loss: 20.8787 - val_digit1_loss: 3.4702 - val_digit2_loss: 3.5188 - val_digit3_loss: 3.4753 - val_digit4_loss: 3.4815 - val_digit5_loss: 3.4566 - val_digit6_loss: 3.4762 - val_digit1_accuracy: 0.0660 - val_digit2_accuracy: 0.0420 - val_digit3_accuracy: 0.0640 - val_digit4_accuracy: 0.0500 - val_digit5_accuracy: 0.0600 - val_digit6_accuracy: 0.0340\nEpoch 11/15\n36/36 - 7s - loss: 18.2685 - digit1_loss: 3.0600 - digit2_loss: 2.9698 - digit3_loss: 2.9722 - digit4_loss: 3.0612 - digit5_loss: 3.0868 - digit6_loss: 3.1184 - digit1_accuracy: 0.1409 - digit2_accuracy: 0.1573 - digit3_accuracy: 0.1558 - digit4_accuracy: 0.1458 - digit5_accuracy: 0.1284 - digit6_accuracy: 0.1291 - val_loss: 20.0823 - val_digit1_loss: 3.3561 - val_digit2_loss: 3.3775 - val_digit3_loss: 3.3643 - val_digit4_loss: 3.3218 - val_digit5_loss: 3.2891 - val_digit6_loss: 3.3735 - val_digit1_accuracy: 0.0880 - val_digit2_accuracy: 0.0540 - val_digit3_accuracy: 0.0880 - val_digit4_accuracy: 0.0820 - val_digit5_accuracy: 0.0920 - val_digit6_accuracy: 0.0640\nEpoch 12/15\n36/36 - 7s - loss: 17.2530 - digit1_loss: 2.9073 - digit2_loss: 2.7549 - digit3_loss: 2.7827 - digit4_loss: 2.8719 - digit5_loss: 2.9576 - digit6_loss: 2.9785 - digit1_accuracy: 0.1751 - digit2_accuracy: 0.2113 - digit3_accuracy: 0.2062 - digit4_accuracy: 0.1838 - digit5_accuracy: 0.1722 - digit6_accuracy: 0.1647 - val_loss: 19.6299 - val_digit1_loss: 3.2289 - val_digit2_loss: 3.2177 - val_digit3_loss: 3.2658 - val_digit4_loss: 3.2994 - val_digit5_loss: 3.2782 - val_digit6_loss: 3.3399 - val_digit1_accuracy: 0.1080 - val_digit2_accuracy: 0.1000 - val_digit3_accuracy: 0.1080 - val_digit4_accuracy: 0.0860 - val_digit5_accuracy: 0.0980 - val_digit6_accuracy: 0.0660\nEpoch 13/15\n36/36 - 7s - loss: 16.3513 - digit1_loss: 2.7567 - digit2_loss: 2.6082 - digit3_loss: 2.6207 - digit4_loss: 2.7110 - digit5_loss: 2.8110 - digit6_loss: 2.8437 - digit1_accuracy: 0.2204 - digit2_accuracy: 0.2362 - digit3_accuracy: 0.2442 - digit4_accuracy: 0.2209 - digit5_accuracy: 0.2051 - digit6_accuracy: 0.1867 - val_loss: 18.1606 - val_digit1_loss: 3.0845 - val_digit2_loss: 2.9781 - val_digit3_loss: 2.9493 - val_digit4_loss: 3.0054 - val_digit5_loss: 3.0186 - val_digit6_loss: 3.1247 - val_digit1_accuracy: 0.1460 - val_digit2_accuracy: 0.1420 - val_digit3_accuracy: 0.1560 - val_digit4_accuracy: 0.1600 - val_digit5_accuracy: 0.1440 - val_digit6_accuracy: 0.1140\nEpoch 14/15\n36/36 - 7s - loss: 13.5619 - digit1_loss: 2.2478 - digit2_loss: 2.1305 - digit3_loss: 2.1314 - digit4_loss: 2.2580 - digit5_loss: 2.3479 - digit6_loss: 2.4463 - digit1_accuracy: 0.3356 - digit2_accuracy: 0.3476 - digit3_accuracy: 0.3627 - digit4_accuracy: 0.3218 - digit5_accuracy: 0.3058 - digit6_accuracy: 0.2933 - val_loss: 15.5372 - val_digit1_loss: 2.6489 - val_digit2_loss: 2.4386 - val_digit3_loss: 2.4616 - val_digit4_loss: 2.5575 - val_digit5_loss: 2.6693 - val_digit6_loss: 2.7612 - val_digit1_accuracy: 0.2140 - val_digit2_accuracy: 0.2760 - val_digit3_accuracy: 0.2340 - val_digit4_accuracy: 0.2360 - val_digit5_accuracy: 0.2160 - val_digit6_accuracy: 0.1720\nEpoch 15/15\n36/36 - 7s - loss: 11.4895 - digit1_loss: 1.9019 - digit2_loss: 1.7813 - digit3_loss: 1.8030 - digit4_loss: 1.8620 - digit5_loss: 2.0229 - digit6_loss: 2.1182 - digit1_accuracy: 0.4096 - digit2_accuracy: 0.4533 - digit3_accuracy: 0.4413 - digit4_accuracy: 0.4220 - digit5_accuracy: 0.3889 - digit6_accuracy: 0.3642 - val_loss: 14.7689 - val_digit1_loss: 2.5386 - val_digit2_loss: 2.3405 - val_digit3_loss: 2.2910 - val_digit4_loss: 2.4121 - val_digit5_loss: 2.5395 - val_digit6_loss: 2.6472 - val_digit1_accuracy: 0.2240 - val_digit2_accuracy: 0.2840 - val_digit3_accuracy: 0.2920 - val_digit4_accuracy: 0.2480 - val_digit5_accuracy: 0.2620 - val_digit6_accuracy: 0.1980\nEpoch 1/15\n36/36 - 7s - loss: 12.7500 - digit1_loss: 2.0721 - digit2_loss: 2.0164 - digit3_loss: 2.0151 - digit4_loss: 2.0877 - digit5_loss: 2.2671 - digit6_loss: 2.2917 - digit1_accuracy: 0.3436 - digit2_accuracy: 0.3709 - digit3_accuracy: 0.3669 - digit4_accuracy: 0.3462 - digit5_accuracy: 0.3087 - digit6_accuracy: 0.3022 - val_loss: 13.8257 - val_digit1_loss: 2.2597 - val_digit2_loss: 2.1833 - val_digit3_loss: 2.2374 - val_digit4_loss: 2.2693 - val_digit5_loss: 2.3920 - val_digit6_loss: 2.4840 - val_digit1_accuracy: 0.3580 - val_digit2_accuracy: 0.3400 - val_digit3_accuracy: 0.2860 - val_digit4_accuracy: 0.3000 - val_digit5_accuracy: 0.3020 - val_digit6_accuracy: 0.2480\nEpoch 2/15\n36/36 - 7s - loss: 9.8977 - digit1_loss: 1.5889 - digit2_loss: 1.5710 - digit3_loss: 1.5786 - digit4_loss: 1.6153 - digit5_loss: 1.7540 - digit6_loss: 1.7899 - digit1_accuracy: 0.4896 - digit2_accuracy: 0.4938 - digit3_accuracy: 0.4856 - digit4_accuracy: 0.4822 - digit5_accuracy: 0.4480 - digit6_accuracy: 0.4371 - val_loss: 12.7778 - val_digit1_loss: 2.0721 - val_digit2_loss: 2.0188 - val_digit3_loss: 2.0596 - val_digit4_loss: 2.1072 - val_digit5_loss: 2.1647 - val_digit6_loss: 2.3554 - val_digit1_accuracy: 0.3600 - val_digit2_accuracy: 0.3940 - val_digit3_accuracy: 0.3680 - val_digit4_accuracy: 0.3620 - val_digit5_accuracy: 0.3300 - val_digit6_accuracy: 0.2860\nEpoch 3/15\n36/36 - 7s - loss: 8.0069 - digit1_loss: 1.2981 - digit2_loss: 1.2513 - digit3_loss: 1.2569 - digit4_loss: 1.3076 - digit5_loss: 1.4376 - digit6_loss: 1.4554 - digit1_accuracy: 0.5704 - digit2_accuracy: 0.5933 - digit3_accuracy: 0.5922 - digit4_accuracy: 0.5747 - digit5_accuracy: 0.5391 - digit6_accuracy: 0.5364 - val_loss: 10.2504 - val_digit1_loss: 1.7000 - val_digit2_loss: 1.6034 - val_digit3_loss: 1.6067 - val_digit4_loss: 1.6824 - val_digit5_loss: 1.7636 - val_digit6_loss: 1.8943 - val_digit1_accuracy: 0.4720 - val_digit2_accuracy: 0.4800 - val_digit3_accuracy: 0.4780 - val_digit4_accuracy: 0.4560 - val_digit5_accuracy: 0.4640 - val_digit6_accuracy: 0.3980\nEpoch 4/15\n36/36 - 7s - loss: 6.7735 - digit1_loss: 1.1295 - digit2_loss: 1.0309 - digit3_loss: 1.0424 - digit4_loss: 1.1303 - digit5_loss: 1.2149 - digit6_loss: 1.2255 - digit1_accuracy: 0.6358 - digit2_accuracy: 0.6622 - digit3_accuracy: 0.6624 - digit4_accuracy: 0.6240 - digit5_accuracy: 0.6089 - digit6_accuracy: 0.6029 - val_loss: 7.8681 - val_digit1_loss: 1.4028 - val_digit2_loss: 1.2059 - val_digit3_loss: 1.2013 - val_digit4_loss: 1.2489 - val_digit5_loss: 1.3768 - val_digit6_loss: 1.4325 - val_digit1_accuracy: 0.5400 - val_digit2_accuracy: 0.5640 - val_digit3_accuracy: 0.5960 - val_digit4_accuracy: 0.6140 - val_digit5_accuracy: 0.5200 - val_digit6_accuracy: 0.5260\nEpoch 5/15\n36/36 - 7s - loss: 5.6133 - digit1_loss: 0.9467 - digit2_loss: 0.8600 - digit3_loss: 0.8704 - digit4_loss: 0.9178 - digit5_loss: 1.0080 - digit6_loss: 1.0103 - digit1_accuracy: 0.6953 - digit2_accuracy: 0.7218 - digit3_accuracy: 0.7231 - digit4_accuracy: 0.7038 - digit5_accuracy: 0.6802 - digit6_accuracy: 0.6809 - val_loss: 7.9747 - val_digit1_loss: 1.3340 - val_digit2_loss: 1.2340 - val_digit3_loss: 1.2591 - val_digit4_loss: 1.2974 - val_digit5_loss: 1.3932 - val_digit6_loss: 1.4572 - val_digit1_accuracy: 0.5680 - val_digit2_accuracy: 0.5740 - val_digit3_accuracy: 0.5800 - val_digit4_accuracy: 0.5780 - val_digit5_accuracy: 0.5440 - val_digit6_accuracy: 0.5200\nEpoch 6/15\n36/36 - 7s - loss: 4.6391 - digit1_loss: 0.7671 - digit2_loss: 0.7311 - digit3_loss: 0.7086 - digit4_loss: 0.7514 - digit5_loss: 0.8538 - digit6_loss: 0.8270 - digit1_accuracy: 0.7518 - digit2_accuracy: 0.7653 - digit3_accuracy: 0.7669 - digit4_accuracy: 0.7551 - digit5_accuracy: 0.7251 - digit6_accuracy: 0.7291 - val_loss: 6.4759 - val_digit1_loss: 1.1569 - val_digit2_loss: 0.9919 - val_digit3_loss: 1.0179 - val_digit4_loss: 1.0483 - val_digit5_loss: 1.1207 - val_digit6_loss: 1.1403 - val_digit1_accuracy: 0.6160 - val_digit2_accuracy: 0.6600 - val_digit3_accuracy: 0.6640 - val_digit4_accuracy: 0.6620 - val_digit5_accuracy: 0.6260 - val_digit6_accuracy: 0.6240\nEpoch 7/15\n36/36 - 7s - loss: 3.8086 - digit1_loss: 0.6234 - digit2_loss: 0.5890 - digit3_loss: 0.5634 - digit4_loss: 0.6225 - digit5_loss: 0.6930 - digit6_loss: 0.7174 - digit1_accuracy: 0.7976 - digit2_accuracy: 0.8040 - digit3_accuracy: 0.8133 - digit4_accuracy: 0.8009 - digit5_accuracy: 0.7787 - digit6_accuracy: 0.7700 - val_loss: 5.7807 - val_digit1_loss: 1.0230 - val_digit2_loss: 0.8929 - val_digit3_loss: 0.8487 - val_digit4_loss: 0.9328 - val_digit5_loss: 1.0660 - val_digit6_loss: 1.0172 - val_digit1_accuracy: 0.6500 - val_digit2_accuracy: 0.7060 - val_digit3_accuracy: 0.7100 - val_digit4_accuracy: 0.7120 - val_digit5_accuracy: 0.6440 - val_digit6_accuracy: 0.6820\nEpoch 8/15\n36/36 - 7s - loss: 3.2760 - digit1_loss: 0.5202 - digit2_loss: 0.5123 - digit3_loss: 0.4931 - digit4_loss: 0.5484 - digit5_loss: 0.5871 - digit6_loss: 0.6149 - digit1_accuracy: 0.8309 - digit2_accuracy: 0.8307 - digit3_accuracy: 0.8424 - digit4_accuracy: 0.8204 - digit5_accuracy: 0.8100 - digit6_accuracy: 0.7933 - val_loss: 5.3626 - val_digit1_loss: 0.9623 - val_digit2_loss: 0.8571 - val_digit3_loss: 0.8416 - val_digit4_loss: 0.8044 - val_digit5_loss: 0.9776 - val_digit6_loss: 0.9196 - val_digit1_accuracy: 0.6600 - val_digit2_accuracy: 0.7220 - val_digit3_accuracy: 0.7180 - val_digit4_accuracy: 0.7280 - val_digit5_accuracy: 0.6900 - val_digit6_accuracy: 0.7080\nEpoch 9/15\n36/36 - 7s - loss: 2.9007 - digit1_loss: 0.4778 - digit2_loss: 0.4615 - digit3_loss: 0.4256 - digit4_loss: 0.4702 - digit5_loss: 0.5285 - digit6_loss: 0.5371 - digit1_accuracy: 0.8420 - digit2_accuracy: 0.8511 - digit3_accuracy: 0.8640 - digit4_accuracy: 0.8422 - digit5_accuracy: 0.8307 - digit6_accuracy: 0.8267 - val_loss: 5.8271 - val_digit1_loss: 1.0304 - val_digit2_loss: 0.9459 - val_digit3_loss: 0.8877 - val_digit4_loss: 0.9758 - val_digit5_loss: 0.9543 - val_digit6_loss: 1.0330 - val_digit1_accuracy: 0.6660 - val_digit2_accuracy: 0.7160 - val_digit3_accuracy: 0.7240 - val_digit4_accuracy: 0.6940 - val_digit5_accuracy: 0.6720 - val_digit6_accuracy: 0.6860\nEpoch 10/15\n36/36 - 7s - loss: 2.5166 - digit1_loss: 0.4149 - digit2_loss: 0.4001 - digit3_loss: 0.3989 - digit4_loss: 0.4074 - digit5_loss: 0.4423 - digit6_loss: 0.4531 - digit1_accuracy: 0.8711 - digit2_accuracy: 0.8693 - digit3_accuracy: 0.8678 - digit4_accuracy: 0.8616 - digit5_accuracy: 0.8542 - digit6_accuracy: 0.8487 - val_loss: 4.9574 - val_digit1_loss: 0.9783 - val_digit2_loss: 0.7527 - val_digit3_loss: 0.7218 - val_digit4_loss: 0.7775 - val_digit5_loss: 0.8731 - val_digit6_loss: 0.8540 - val_digit1_accuracy: 0.6740 - val_digit2_accuracy: 0.7640 - val_digit3_accuracy: 0.7640 - val_digit4_accuracy: 0.7460 - val_digit5_accuracy: 0.7300 - val_digit6_accuracy: 0.7280\nEpoch 11/15\n36/36 - 7s - loss: 2.1780 - digit1_loss: 0.3779 - digit2_loss: 0.3329 - digit3_loss: 0.3319 - digit4_loss: 0.3577 - digit5_loss: 0.3859 - digit6_loss: 0.3917 - digit1_accuracy: 0.8784 - digit2_accuracy: 0.8904 - digit3_accuracy: 0.8880 - digit4_accuracy: 0.8820 - digit5_accuracy: 0.8744 - digit6_accuracy: 0.8731 - val_loss: 5.5851 - val_digit1_loss: 1.0978 - val_digit2_loss: 0.8725 - val_digit3_loss: 0.8150 - val_digit4_loss: 0.8439 - val_digit5_loss: 0.9833 - val_digit6_loss: 0.9725 - val_digit1_accuracy: 0.6600 - val_digit2_accuracy: 0.7400 - val_digit3_accuracy: 0.7560 - val_digit4_accuracy: 0.7680 - val_digit5_accuracy: 0.7080 - val_digit6_accuracy: 0.7480\nEpoch 12/15\n36/36 - 7s - loss: 1.9177 - digit1_loss: 0.3137 - digit2_loss: 0.2884 - digit3_loss: 0.3010 - digit4_loss: 0.3122 - digit5_loss: 0.3472 - digit6_loss: 0.3552 - digit1_accuracy: 0.8984 - digit2_accuracy: 0.9007 - digit3_accuracy: 0.9062 - digit4_accuracy: 0.8960 - digit5_accuracy: 0.8811 - digit6_accuracy: 0.8847 - val_loss: 4.8609 - val_digit1_loss: 0.8780 - val_digit2_loss: 0.7376 - val_digit3_loss: 0.7483 - val_digit4_loss: 0.8083 - val_digit5_loss: 0.8434 - val_digit6_loss: 0.8453 - val_digit1_accuracy: 0.7280 - val_digit2_accuracy: 0.7920 - val_digit3_accuracy: 0.7740 - val_digit4_accuracy: 0.7580 - val_digit5_accuracy: 0.7460 - val_digit6_accuracy: 0.7360\nEpoch 13/15\n36/36 - 7s - loss: 1.7113 - digit1_loss: 0.2846 - digit2_loss: 0.2701 - digit3_loss: 0.2694 - digit4_loss: 0.2911 - digit5_loss: 0.2882 - digit6_loss: 0.3078 - digit1_accuracy: 0.9036 - digit2_accuracy: 0.9122 - digit3_accuracy: 0.9127 - digit4_accuracy: 0.9038 - digit5_accuracy: 0.9056 - digit6_accuracy: 0.8956 - val_loss: 5.0364 - val_digit1_loss: 0.8832 - val_digit2_loss: 0.8403 - val_digit3_loss: 0.7667 - val_digit4_loss: 0.7990 - val_digit5_loss: 0.8708 - val_digit6_loss: 0.8764 - val_digit1_accuracy: 0.7380 - val_digit2_accuracy: 0.7620 - val_digit3_accuracy: 0.7640 - val_digit4_accuracy: 0.7580 - val_digit5_accuracy: 0.7500 - val_digit6_accuracy: 0.7500\nEpoch 14/15\n36/36 - 7s - loss: 1.5764 - digit1_loss: 0.2716 - digit2_loss: 0.2519 - digit3_loss: 0.2393 - digit4_loss: 0.2485 - digit5_loss: 0.2876 - digit6_loss: 0.2774 - digit1_accuracy: 0.9124 - digit2_accuracy: 0.9140 - digit3_accuracy: 0.9227 - digit4_accuracy: 0.9169 - digit5_accuracy: 0.9073 - digit6_accuracy: 0.9133 - val_loss: 4.7869 - val_digit1_loss: 0.9020 - val_digit2_loss: 0.7494 - val_digit3_loss: 0.7361 - val_digit4_loss: 0.7685 - val_digit5_loss: 0.8133 - val_digit6_loss: 0.8175 - val_digit1_accuracy: 0.7300 - val_digit2_accuracy: 0.7760 - val_digit3_accuracy: 0.7860 - val_digit4_accuracy: 0.7660 - val_digit5_accuracy: 0.7740 - val_digit6_accuracy: 0.7560\nEpoch 15/15\n36/36 - 7s - loss: 1.3544 - digit1_loss: 0.2322 - digit2_loss: 0.2128 - digit3_loss: 0.1957 - digit4_loss: 0.2230 - digit5_loss: 0.2438 - digit6_loss: 0.2470 - digit1_accuracy: 0.9269 - digit2_accuracy: 0.9327 - digit3_accuracy: 0.9378 - digit4_accuracy: 0.9271 - digit5_accuracy: 0.9213 - digit6_accuracy: 0.9184 - val_loss: 4.7352 - val_digit1_loss: 0.9278 - val_digit2_loss: 0.7882 - val_digit3_loss: 0.7164 - val_digit4_loss: 0.7421 - val_digit5_loss: 0.7892 - val_digit6_loss: 0.7716 - val_digit1_accuracy: 0.7140 - val_digit2_accuracy: 0.7700 - val_digit3_accuracy: 0.7840 - val_digit4_accuracy: 0.7840 - val_digit5_accuracy: 0.7680 - val_digit6_accuracy: 0.7900\nEpoch 1/15\n36/36 - 7s - loss: 5.6839 - digit1_loss: 0.9463 - digit2_loss: 0.8800 - digit3_loss: 0.8872 - digit4_loss: 0.9360 - digit5_loss: 1.0260 - digit6_loss: 1.0085 - digit1_accuracy: 0.7196 - digit2_accuracy: 0.7344 - digit3_accuracy: 0.7336 - digit4_accuracy: 0.7171 - digit5_accuracy: 0.6967 - digit6_accuracy: 0.6993 - val_loss: 3.3678 - val_digit1_loss: 0.4691 - val_digit2_loss: 0.5873 - val_digit3_loss: 0.4485 - val_digit4_loss: 0.5945 - val_digit5_loss: 0.6493 - val_digit6_loss: 0.6191 - val_digit1_accuracy: 0.8420 - val_digit2_accuracy: 0.8140 - val_digit3_accuracy: 0.8580 - val_digit4_accuracy: 0.8220 - val_digit5_accuracy: 0.7800 - val_digit6_accuracy: 0.7960\nEpoch 2/15\n36/36 - 7s - loss: 3.4767 - digit1_loss: 0.5851 - digit2_loss: 0.5380 - digit3_loss: 0.5290 - digit4_loss: 0.5722 - digit5_loss: 0.6315 - digit6_loss: 0.6210 - digit1_accuracy: 0.8136 - digit2_accuracy: 0.8318 - digit3_accuracy: 0.8336 - digit4_accuracy: 0.8144 - digit5_accuracy: 0.7962 - digit6_accuracy: 0.8022 - val_loss: 2.8162 - val_digit1_loss: 0.4012 - val_digit2_loss: 0.4391 - val_digit3_loss: 0.4017 - val_digit4_loss: 0.4908 - val_digit5_loss: 0.5805 - val_digit6_loss: 0.5029 - val_digit1_accuracy: 0.8680 - val_digit2_accuracy: 0.8660 - val_digit3_accuracy: 0.8680 - val_digit4_accuracy: 0.8480 - val_digit5_accuracy: 0.8280 - val_digit6_accuracy: 0.8360\nEpoch 3/15\n36/36 - 7s - loss: 2.7762 - digit1_loss: 0.4850 - digit2_loss: 0.4315 - digit3_loss: 0.4077 - digit4_loss: 0.4438 - digit5_loss: 0.5054 - digit6_loss: 0.5027 - digit1_accuracy: 0.8444 - digit2_accuracy: 0.8616 - digit3_accuracy: 0.8673 - digit4_accuracy: 0.8596 - digit5_accuracy: 0.8384 - digit6_accuracy: 0.8371 - val_loss: 3.1275 - val_digit1_loss: 0.4620 - val_digit2_loss: 0.4980 - val_digit3_loss: 0.4426 - val_digit4_loss: 0.6101 - val_digit5_loss: 0.5978 - val_digit6_loss: 0.5170 - val_digit1_accuracy: 0.8500 - val_digit2_accuracy: 0.8580 - val_digit3_accuracy: 0.8680 - val_digit4_accuracy: 0.8240 - val_digit5_accuracy: 0.8200 - val_digit6_accuracy: 0.8340\nEpoch 4/15\n36/36 - 7s - loss: 2.1782 - digit1_loss: 0.3673 - digit2_loss: 0.3513 - digit3_loss: 0.3273 - digit4_loss: 0.3717 - digit5_loss: 0.3788 - digit6_loss: 0.3818 - digit1_accuracy: 0.8789 - digit2_accuracy: 0.8822 - digit3_accuracy: 0.8973 - digit4_accuracy: 0.8780 - digit5_accuracy: 0.8758 - digit6_accuracy: 0.8764 - val_loss: 3.0365 - val_digit1_loss: 0.4623 - val_digit2_loss: 0.4398 - val_digit3_loss: 0.4421 - val_digit4_loss: 0.5479 - val_digit5_loss: 0.5853 - val_digit6_loss: 0.5591 - val_digit1_accuracy: 0.8480 - val_digit2_accuracy: 0.8580 - val_digit3_accuracy: 0.8680 - val_digit4_accuracy: 0.8380 - val_digit5_accuracy: 0.8280 - val_digit6_accuracy: 0.8320\nEpoch 5/15\n36/36 - 7s - loss: 1.8654 - digit1_loss: 0.3242 - digit2_loss: 0.2891 - digit3_loss: 0.2755 - digit4_loss: 0.3215 - digit5_loss: 0.3302 - digit6_loss: 0.3248 - digit1_accuracy: 0.8936 - digit2_accuracy: 0.9027 - digit3_accuracy: 0.9096 - digit4_accuracy: 0.9007 - digit5_accuracy: 0.8922 - digit6_accuracy: 0.8980 - val_loss: 2.5891 - val_digit1_loss: 0.3780 - val_digit2_loss: 0.3807 - val_digit3_loss: 0.3512 - val_digit4_loss: 0.4711 - val_digit5_loss: 0.5076 - val_digit6_loss: 0.5004 - val_digit1_accuracy: 0.8800 - val_digit2_accuracy: 0.8760 - val_digit3_accuracy: 0.8820 - val_digit4_accuracy: 0.8580 - val_digit5_accuracy: 0.8400 - val_digit6_accuracy: 0.8620\nEpoch 6/15\n36/36 - 7s - loss: 1.5665 - digit1_loss: 0.2715 - digit2_loss: 0.2442 - digit3_loss: 0.2296 - digit4_loss: 0.2722 - digit5_loss: 0.2722 - digit6_loss: 0.2767 - digit1_accuracy: 0.9120 - digit2_accuracy: 0.9213 - digit3_accuracy: 0.9262 - digit4_accuracy: 0.9162 - digit5_accuracy: 0.9124 - digit6_accuracy: 0.9124 - val_loss: 2.4572 - val_digit1_loss: 0.3853 - val_digit2_loss: 0.3289 - val_digit3_loss: 0.3171 - val_digit4_loss: 0.4378 - val_digit5_loss: 0.5121 - val_digit6_loss: 0.4760 - val_digit1_accuracy: 0.8760 - val_digit2_accuracy: 0.8880 - val_digit3_accuracy: 0.8980 - val_digit4_accuracy: 0.8840 - val_digit5_accuracy: 0.8380 - val_digit6_accuracy: 0.8520\nEpoch 7/15\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-49d04f117643>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m        \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m        \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m        \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m        )\n",
      "\u001b[1;32mC:\\Users\\tingw\\Anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\tingw\\Anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\tingw\\Anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\tingw\\Anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    609\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\tingw\\Anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\tingw\\Anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1665\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\tingw\\Anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\tingw\\Anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\Users\\tingw\\Anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs=15\n",
    "batch_size=128\n",
    "big_batch_size=5000\n",
    "train_data_gen=iter(train_data01.repeat().batch(big_batch_size))\n",
    "\n",
    "for i in range(int(num_elements/big_batch_size)):\n",
    "   img , lb = next(train_data_gen)\n",
    "   history = model.fit(\n",
    "       img,\n",
    "       lb,\n",
    "       batch_size=batch_size,\n",
    "       validation_split=0.1,\n",
    "       shuffle=True,\n",
    "       use_multiprocessing=True,\n",
    "       epochs=epochs,\n",
    "       verbose=2\n",
    "       )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseResult(RS):\n",
    "    for j in range(len(RS)):\n",
    "        PredChr=''\n",
    "        for i in range(6):\n",
    "            PredChr+= CLASS_NAMES[(np.where(RS[j][i] == RS[j][i].max())[0][0])]\n",
    "        if j == 0:\n",
    "            LB = [PredChr]\n",
    "        else:\n",
    "            LB.append(PredChr)      \n",
    "    return LB\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output to CSV\n",
    "VDlabel = np.array([])\n",
    "img = next(iter(val_data01.batch(10000)))\n",
    "result = model.predict(img,use_multiprocessing = True)\n",
    "result = np.array(result).reshape((10000,6,36))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dir = tf.data.Dataset.list_files(val_dir_data01+'*.jpg',shuffle=False) \n",
    "test = parseResult(result)\n",
    "val_file_name = pd.read_csv(\"./dev/data01_dev.csv\")\n",
    "val_file_name.join(pd.DataFrame(test,columns=[\"code\"])).to_csv(\"data01_dev.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitmyenvcondac89683127ca741bc84ed6db3ffcad32d",
   "display_name": "Python 3.7.7 64-bit ('myenv': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}