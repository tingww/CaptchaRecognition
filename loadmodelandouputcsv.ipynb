{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"h5s/data02/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no crop function\n",
    "def parse_label(strIN):\n",
    "    return (strIN==CLASS_NAMES).astype(float)\n",
    "def readimg_to_tensor(fn):\n",
    "    a = tf.io.read_file((fn))\n",
    "    img = tf.io.decode_jpeg(a)\n",
    "    #*********\n",
    "    #img = tf.image.adjust_contrast(img, 2)\n",
    "    #*********\n",
    "    img = tf.image.convert_image_dtype(img, dtype=tf.float16)/255.\n",
    "    img = tf.image.per_image_standardization(img)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CLASS_NAMES = np.array([])\n",
    "for i in range(10):\n",
    "    CLASS_NAMES =np.append(CLASS_NAMES,chr(ord(\"0\")+i))\n",
    "for i in range(26):\n",
    "    CLASS_NAMES = np.append(CLASS_NAMES,chr(ord(\"A\")+i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseResult(RS):\n",
    "    for j in range(len(RS[0])):\n",
    "        PredChr=''\n",
    "        for i in range(6):\n",
    "            PredChr+= CLASS_NAMES[(np.where(RS[i][j] == RS[i][j].max())[0][0])]\n",
    "        if j == 0:\n",
    "            LB = [PredChr]\n",
    "        else:\n",
    "            LB.append(PredChr)      \n",
    "    return LB\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_paths=[\"railway_d2e-1.hdf5\",\"CNN_GRU_3_fine2.hdf5\",\"CNN_GRU_4.hdf5\",\"CNN_GRU_5.hdf5\",\"CNN+GRU.hdf5\",\"CNN_GRU_2.hdf5\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_chr(model_paths,img_test):\n",
    "    '''return the most probable characters for given models'''\n",
    "    models = []\n",
    "    for m in model_paths:\n",
    "        models.append(tf.keras.models.load_model(filepath+m))\n",
    "    result = []\n",
    "    for m in models:\n",
    "        result.append(m.predict(img_test))\n",
    "    r = np.array(result)\n",
    "    a = np.argmax(r,axis=3)\n",
    "    a = a.transpose()\n",
    "    a_p = np.max(r,axis=3)\n",
    "    a_p = a_p.transpose()\n",
    "    #return the most probable character index\n",
    "    vote_outcome=[]\n",
    "    for j in range(len(a)):\n",
    "        chr = ''\n",
    "        for i,p in zip(a[j],a_p[j]):\n",
    "            if(all(i==i[0])):\n",
    "                chr+=(CLASS_NAMES[i[0]])\n",
    "            else:\n",
    "                maj = np.bincount(i).argmax()   #i[np.argmax(p)]\n",
    "                chr+=(CLASS_NAMES[maj])           \n",
    "        vote_outcome.append(chr)\n",
    "    \n",
    "    return vote_outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#01\n",
    "val_dir_data = os.path.abspath(os.getcwd())+\"\\\\test\\\\data01_test\"\n",
    "#validation data no crop\n",
    "val_dir = tf.data.Dataset.list_files(val_dir_data+'*.jpg',shuffle=False) \n",
    "val_data = val_dir.map(lambda x: readimg_to_tensor(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output to CSV\n",
    "VDlabel = np.array([])\n",
    "img = next(iter(val_data.batch(10000)))\n",
    "result = model.predict(img,use_multiprocessing = True)\n",
    "test = parseResult(result)\n",
    "val_file_name = pd.read_csv(\"./test/data01_test.csv\")\n",
    "val_file_name.join(pd.DataFrame(test,columns=[\"code\"])).to_csv(\"data01_test.csv\",index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#02\n",
    "val_dir_data02 = os.path.abspath(os.getcwd())+\"\\\\test\\\\data02_test\"\n",
    "#validation data no crop\n",
    "val_dir = tf.data.Dataset.list_files(val_dir_data02+'*.jpg',shuffle=False) \n",
    "val_data02 = val_dir.map(lambda x: readimg_to_tensor(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output to CSV\n",
    "img = next(iter(val_data02.batch(10000)))\n",
    "test = ensemble_chr(model_paths,img)\n",
    "val_file_name = pd.read_csv(\"./dev/data02_dev.csv\")\n",
    "val_file_name.join(pd.DataFrame(test,columns=[\"code\"])).to_csv(\"data02_test.csv\",index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output to CSV\n",
    "VDlabel = np.array([])\n",
    "img = next(iter(val_data02.batch(10000)))\n",
    "result = model.predict(img,use_multiprocessing = True)\n",
    "val_dir = tf.data.Dataset.list_files(val_dir_data02+'*.jpg',shuffle=False) \n",
    "test = parseResult(result)\n",
    "val_file_name = pd.read_csv(\"./dev/data02_dev.csv\")\n",
    "val_file_name.join(pd.DataFrame(test,columns=[\"code\"])).to_csv(\"data02_dev.csv\",index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize\n",
    "def show_model_vision(model,img):\n",
    "    \n",
    "    img_tensor = tf.expand_dims(img[np.random.randint(10000)],0)\n",
    "    result = model(img_tensor)\n",
    "    PredChr=''\n",
    "    for i in range(6):\n",
    "        PredChr+= (\n",
    "            CLASS_NAMES[\n",
    "            np.where(result[i].numpy()[0] == result[i].numpy()[0].max())[0][0]\n",
    "            ])\n",
    "    \n",
    "    print(\"Predict character: \"+ PredChr)\n",
    "    # Extracts the outputs of the top 8 layers:\n",
    "    layer_outputs = [layer.output for layer in model.layers[:] if hasattr(layer,\"kernel_size\") and getattr(layer,\"kernel_size\")==(3,3)]\n",
    "    # Creates a model that will return these outputs, given the model input:\n",
    "    activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n",
    "    # one array per layer activation\n",
    "    activations = activation_model.predict(img_tensor)\n",
    "    \n",
    "    # These are the names of the layers, so can have them as part of our plot\n",
    "    layer_names = []\n",
    "    for layer in model.layers[:]:\n",
    "        if hasattr(layer,\"kernel_size\") and getattr(layer,\"kernel_size\")==(3,3):\n",
    "            layer_names.append(layer.name) \n",
    "\n",
    "    images_per_row = 3\n",
    "    # Now let's display our feature maps\n",
    "    k=1\n",
    "    for layer_name, layer_activation in zip(layer_names, activations):\n",
    "        for n in range(images_per_row):\n",
    "            ax = plt.subplot(len(layer_names),images_per_row,k)\n",
    "            plt.imshow(layer_activation[0, :, :,np.random.randint(layer_activation.shape[-1]) ], cmap='viridis')\n",
    "            plt.title(layer_name)\n",
    "            plt.axis('image')\n",
    "            plt.tight_layout()\n",
    "            k+=1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(30,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_model_vision(model,img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 紀錄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data 01\n",
    "\n",
    "Raiway_ini_and_WR_L0.4383.hdf5  95.47%\n",
    "\n",
    "ResNet_small_4_mixSGD_.40.hdf5  93.74%\n",
    "\n",
    "ResNet_small_4_mixSGD_.57587.hdf5 92.87%\n",
    "\n",
    "ResNet_small_4_mixSGD_.4219.hdf5 92.68%\n",
    "\n",
    "railway_2_wr1e-3.hdf5 97.24%\n",
    "\n",
    "railway_2_wr_5e-3.hdf5 97.72%\n",
    "\n",
    "railway_2_d12e-2.hdf5 97.53%\n",
    "\n",
    "railway_2_b64_wr5e-3.hdf5 97.54%\n",
    "\n",
    "railway_2_b256_wr5e-3.hdf5 97.74%\n",
    "\n",
    "railway_2_b256_wr5e-3 (1).hdf5 97.74%\n",
    "\n",
    "railway_2_b256_wr5e-31.hdf5 97.9%\n",
    "\n",
    "railway_aug_d3e-1.hdf5 97.44%\n",
    "\n",
    "railway_aug_d3e-1 copy.hdf5 97.49%\n",
    "\n",
    "\n",
    "\n",
    "## data 02\n",
    "\n",
    "railway_d2e-1.hdf5  94.87%\n",
    "\n",
    "railway_d3e-1.hdf5  94.58%\n",
    "\n",
    "## test 01\n",
    "\n",
    "slyneGA_wr2.hdf5    98.11%\n",
    "\n",
    "railway_2_b256_wr5e-31.hdf5 97.99%\n",
    "\n",
    "slyneGA_wr2-1.hdf5  97.8%\n",
    "\n",
    "slyneGA_wr2-2.hdf5  98.35%  / val:98.78%\n",
    "\n",
    "slyneGA_wr2-3.hdf5  98.53%  / val:98.9%\n",
    "\n",
    "slyneGA_GRU2.hdf5  98.64%  / val:98.888%  ***********\n",
    "\n",
    "slyneGA_GRU.hdf5  98.51%  / val:98.888%\n",
    "\n",
    "slyneGA_GRU3.hdf5 98.61% / val:98.84%\n",
    "\n",
    "## test 02\n",
    "\n",
    "1. 多數決\n",
    "\n",
    "\"railway_d2e-1.hdf5\",\"CNN_GRU_3_fine2.hdf5\",\"CNN_GRU_4.hdf5\",\"CNN_GRU_5.hdf5\",\"CNN+GRU.hdf5\",\"CNN_GRU_2.hdf5\" \n",
    "\n",
    "val: 97.46%     test:97.39 %  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitmyenvcondac89683127ca741bc84ed6db3ffcad32d",
   "display_name": "Python 3.7.7 64-bit ('myenv': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}