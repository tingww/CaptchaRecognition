{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train data count: 50000\nValidation data count: 10000\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         filename code0\n0      000000.jpg     Z\n1      000001.jpg     V\n2      000002.jpg     J\n3      000003.jpg     X\n4      000004.jpg     H\n...           ...   ...\n49995  049995.jpg     3\n49996  049996.jpg     4\n49997  049997.jpg     C\n49998  049998.jpg     K\n49999  049999.jpg     8\n\n[50000 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>code0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000000.jpg</td>\n      <td>Z</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000001.jpg</td>\n      <td>V</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000002.jpg</td>\n      <td>J</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>000003.jpg</td>\n      <td>X</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>000004.jpg</td>\n      <td>H</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49995</th>\n      <td>049995.jpg</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>049996.jpg</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>049997.jpg</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>049998.jpg</td>\n      <td>K</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>049999.jpg</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n<p>50000 rows Ã— 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D,BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 15\n",
    "IMG_HEIGHT = 60\n",
    "IMG_WIDTH = 30\n",
    "CLASS_NAMES = np.array([])\n",
    "for i in range(10):\n",
    "    CLASS_NAMES =np.append(CLASS_NAMES,chr(ord(\"0\")+i))\n",
    "for i in range(26):\n",
    "    CLASS_NAMES = np.append(CLASS_NAMES,chr(ord(\"A\")+i))\n",
    "\n",
    "#training dir / validation dir\n",
    "train_dir_data01 = os.path.abspath(os.getcwd())+\"\\\\train\\\\data01_train\\\\\"\n",
    "val_dir_data01 = os.path.abspath(os.getcwd())+\"\\\\dev\\\\data01_dev\"\n",
    "num_train_data01 = len(os.listdir(train_dir_data01))\n",
    "num_val_data01 = len(os.listdir(val_dir_data01))\n",
    "print(\"Train data count: \" + str(num_train_data01))\n",
    "print(\"Validation data count: \" + str(num_val_data01))\n",
    "\n",
    "#store filename and label to a Dataframe \n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"train\\\\data01_train.csv\")\n",
    "for i in range(len(data)):\n",
    "    data.iloc[i,1] = list(data.iloc[i,1])\n",
    "\n",
    "#maybe there's an easier way to separate labels??\n",
    "arr = np.zeros([6,50000],str)\n",
    "for j in range(6):\n",
    "    for i in range(len(data)):\n",
    "        arr[j][i] = data.iloc[i,1][j]\n",
    "data = data.drop(columns= [\"code\"]).join(pd.DataFrame(arr.transpose(),columns = [\"code0\",\"code1\",'code2','code3','code4','code5']))\n",
    "\n",
    "#for testing model\n",
    "data = data.drop(columns=[\"code1\",\"code2\",\"code3\",\"code4\",\"code5\"])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = tf.data.Dataset.from_tensor_slices(data.iloc[:,1])\n",
    "def parse_label(strIN):\n",
    "    return tf.expand_dims(strIN==CLASS_NAMES,0)\n",
    "\n",
    "def cropimage_operation(fn):\n",
    "    a = tf.io.read_file((fn))\n",
    "        #crop to [60,30,3]\n",
    "    img = tf.image.decode_and_crop_jpeg(a,[0,0,IMG_HEIGHT,IMG_WIDTH],channels=3)\n",
    "    return tf.expand_dims(img,0)\n",
    "\n",
    "train_label01 = label.map(parse_label)\n",
    "train_dir01 = tf.data.Dataset.list_files(train_dir_data01+'*.jpg',shuffle=False)\n",
    "train_data01 = tf.data.Dataset.zip((train_dir01.map(cropimage_operation),train_label01))\n",
    "\n",
    "def show_batch(image_batchh, label_batchh):\n",
    "  plt.figure(figsize=(14,10))\n",
    "  for n in range(25):\n",
    "      ax = plt.subplot(5,5,n+1)\n",
    "      plt.imshow(image_batchh[n][0])\n",
    "      plt.title(CLASS_NAMES[np.where(label_batch[n][0])])\n",
    "      plt.axis('image')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_1 (Conv2D)            (None, 60, 30, 64)        15616     \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 30, 15, 64)        0         \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 30, 15, 64)        120       \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 30, 15, 64)        331840    \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 30, 15, 64)        120       \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 15, 7, 64)         0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 15, 7, 64)         200768    \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 15, 7, 32)         100384    \n_________________________________________________________________\nflatten (Flatten)            (None, 3360)              0         \n_________________________________________________________________\ndense (Dense)                (None, 36)                120996    \n=================================================================\nTotal params: 769,844\nTrainable params: 769,724\nNon-trainable params: 120\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(64, (9, 9), input_shape=(IMG_HEIGHT, IMG_WIDTH ,3), padding='same',\n",
    "           activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2),strides=2),\n",
    "    BatchNormalization(axis=1),\n",
    "    Conv2D(64, (9, 9), activation='relu', padding='same'),     \n",
    "    BatchNormalization(axis=1),\n",
    "    MaxPooling2D(pool_size=(2,2),strides=2),\n",
    "    Conv2D(64, (7, 7), activation='relu', padding='same'),\n",
    "    Conv2D(32, (7, 7), activation='relu', padding='same',),   \n",
    "    Flatten(),\n",
    "    Dense(36,activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/15\n390/390 [==============================] - 2s 6ms/step - loss: 3.5838 - accuracy: 0.0256\nEpoch 2/15\n390/390 [==============================] - 2s 6ms/step - loss: 3.5803 - accuracy: 0.0462\nEpoch 3/15\n390/390 [==============================] - 2s 6ms/step - loss: 3.5809 - accuracy: 0.0308\nEpoch 4/15\n390/390 [==============================] - 2s 6ms/step - loss: 3.5841 - accuracy: 0.0256\nEpoch 5/15\n390/390 [==============================] - 2s 6ms/step - loss: 3.5815 - accuracy: 0.0308\nEpoch 6/15\n390/390 [==============================] - 2s 6ms/step - loss: 3.5853 - accuracy: 0.0359\nEpoch 7/15\n390/390 [==============================] - 2s 6ms/step - loss: 3.5821 - accuracy: 0.0282\nEpoch 8/15\n390/390 [==============================] - 2s 6ms/step - loss: 3.5830 - accuracy: 0.0231\nEpoch 9/15\n390/390 [==============================] - 2s 6ms/step - loss: 3.5858 - accuracy: 0.0231\nEpoch 10/15\n390/390 [==============================] - 2s 6ms/step - loss: 3.5817 - accuracy: 0.0282\nEpoch 11/15\n390/390 [==============================] - 2s 6ms/step - loss: 3.5836 - accuracy: 0.0308\nEpoch 12/15\n390/390 [==============================] - 2s 6ms/step - loss: 3.5810 - accuracy: 0.0385\nEpoch 13/15\n390/390 [==============================] - 2s 6ms/step - loss: 3.5797 - accuracy: 0.0308\nEpoch 14/15\n390/390 [==============================] - 2s 6ms/step - loss: 3.5826 - accuracy: 0.0333\nEpoch 15/15\n390/390 [==============================] - 2s 6ms/step - loss: 3.5813 - accuracy: 0.0333\n"
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_data01,\n",
    "    batch_size=batch_size,\n",
    "    steps_per_epoch=50000// batch_size, \n",
    "    epochs=epochs,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sigle_img(imgdir):\n",
    "    imgtest2 = plt.imread(imgdir)\n",
    "    imgtest2 = np.expand_dims(imgtest2, axis=0)\n",
    "    result = model(imgtest2)\n",
    "    PredChr = CLASS_NAMES[\n",
    "        np.where(result.numpy()[0] == result.numpy()[0].max())[0][0]\n",
    "    ]\n",
    "    print(\"Predict character: \"+ PredChr)\n",
    "    return model(imgtest2)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitmyenvcondac89683127ca741bc84ed6db3ffcad32d",
   "display_name": "Python 3.7.7 64-bit ('myenv': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}